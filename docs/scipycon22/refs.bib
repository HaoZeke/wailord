
@book{ahoCompilersPrinciplesTechniques2007,
  title = {Compilers: Principles, Techniques, \& Tools},
  shorttitle = {Compilers},
  editor = {Aho, Alfred V. and Aho, Alfred V.},
  date = {2007},
  edition = {2nd ed},
  publisher = {{Pearson/Addison Wesley}},
  location = {{Boston}},
  isbn = {978-0-321-48681-3},
  langid = {english},
  pagetotal = {1009},
  keywords = {Compilers (Computer programs)},
  annotation = {OCLC: ocm70775643}
}

@incollection{asgeirssonExploringPotentialEnergy2018,
  ids = {asgeirssonExploringPotentialEnergy2018a},
  title = {Exploring {{Potential Energy Surfaces}} with {{Saddle Point Searches}}},
  booktitle = {Handbook of {{Materials Modeling}}},
  author = {Ásgeirsson, Vilhjálmur and Jónsson, Hannes},
  editor = {Andreoni, Wanda and Yip, Sidney},
  date = {2018},
  pages = {1--26},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-42913-7_28-1},
  url = {http://link.springer.com/10.1007/978-3-319-42913-7_28-1},
  urldate = {2020-03-02},
  abstract = {The energy surface of an atomic scale representation of a material contains the essential information needed to determine the structure and time evolution of the system at a given temperature. Local minima on the surface represent (meta)stable states of the system, while first-order saddle points characterize the mechanisms of transitions between states. While many well-known methods make it relatively easy to find local minima, the identification of saddle points is more challenging. In this chapter, methods for finding saddle points are discussed as well as applications to materials simulations. Both doubly constrained search methods, where the final and the initial state minima are specified, and singly constrained search methods, where only the initial state is specified, are discussed. The focus is on a classical description of the atom coordinates, but saddle points corresponding to quantum mechanical tunneling are also mentioned. An extension to magnetic systems where the energy surface depends on the orientation of the magnetic vectors is sketched.},
  isbn = {978-3-319-42913-7},
  langid = {english}
}

@inproceedings{bhatEvaluatingEfficacyTestdriven2006,
  title = {Evaluating the Efficacy of Test-Driven Development: Industrial Case Studies},
  shorttitle = {Evaluating the Efficacy of Test-Driven Development},
  booktitle = {Proceedings of the 2006 {{ACM}}/{{IEEE}} International Symposium on {{Empirical}} Software Engineering},
  author = {Bhat, Thirumalesh and Nagappan, Nachiappan},
  date = {2006-09-21},
  series = {{{ISESE}} '06},
  pages = {356--363},
  publisher = {{Association for Computing Machinery}},
  location = {{New York, NY, USA}},
  doi = {10.1145/1159733.1159787},
  url = {https://doi.org/10.1145/1159733.1159787},
  urldate = {2022-06-29},
  abstract = {This paper discusses software development using the Test Driven Development (TDD) methodology in two different environments (Windows and MSN divisions) at Microsoft. In both these case studies we measure the various context, product and outcome measures to compare and evaluate the efficacy of TDD. We observed a significant increase in quality of the code (greater than two times) for projects developed using TDD compared to similar projects developed in the same organization in a non-TDD fashion. The projects also took at least 15\% extra upfront time for writing the tests. Additionally, the unit tests have served as auto documentation for the code when libraries/APIs had to be used as well as for code maintenance.},
  isbn = {978-1-59593-218-1},
  keywords = {software quality,test-driven development}
}

@unpublished{blumRecoveringBiasedData2019,
  title = {Recovering from {{Biased Data}}: {{Can Fairness Constraints Improve Accuracy}}?},
  shorttitle = {Recovering from {{Biased Data}}},
  author = {Blum, Avrim and Stangl, Kevin},
  date = {2019-12-02},
  eprint = {1912.01094},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/1912.01094},
  urldate = {2020-06-16},
  abstract = {Multiple fairness constraints have been proposed in the literature, motivated by a range of concerns about how demographic groups might be treated unfairly by machine learning classifiers. In this work we consider a different motivation; learning from biased training data. We posit several ways in which training data may be biased, including having a more noisy or negatively biased labeling process on members of a disadvantaged group, or a decreased prevalence of positive or negative examples from the disadvantaged group, or both. Given such biased training data, Empirical Risk Minimization (ERM) may produce a classifier that not only is biased but also has suboptimal accuracy on the true data distribution. We examine the ability of fairness-constrained ERM to correct this problem. In particular, we find that the Equal Opportunity fairness constraint (Hardt, Price, and Srebro 2016) combined with ERM will provably recover the Bayes Optimal Classifier under a range of bias models. We also consider other recovery methods including reweighting the training data, Equalized Odds, and Demographic Parity. These theoretical results provide additional motivation for considering fairness interventions even if an actor cares primarily about accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@software{communityTuringWayHandbook2019,
  title = {The {{Turing Way}}: {{A Handbook}} for {{Reproducible Data Science}}},
  shorttitle = {The {{Turing Way}}},
  author = {Community, The Turing Way and Arnold, Becky and Bowler, Louise and Gibson, Sarah and Herterich, Patricia and Higman, Rosie and Krystalli, Anna and Morley, Alexander and O'Reilly, Martin and Whitaker, Kirstie},
  date = {2019-03-25},
  url = {https://doi.org/10.5281/zenodo.3233986},
  urldate = {2020-09-20},
  abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists.{$<$}em{$>$} {$<$}/em{$><$}em{$>$}The Turing Way{$<$}/em{$>$} is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. {$<$}strong{$>$}Release log{$<$}/strong{$>$} {$<$}strong{$>$}v0.0.4:{$<$}/strong{$>$} Continuous integration chapter merged to master. {$<$}strong{$>$}v0.0.3:{$<$}/strong{$>$} Reproducible environments chapter merged to master. {$<$}strong{$>$}v0.0.2:{$<$}/strong{$>$} Version control chapter merged to master. {$<$}strong{$>$}v0.0.1: {$<$}/strong{$>$}Reproducibility chapter merged to master.},
  organization = {{Zenodo}},
  version = {v0.0.4},
  keywords = {archived},
  annotation = {00000}
}

@article{deComparingMoleculesSolids2016,
  title = {Comparing Molecules and Solids across Structural and Alchemical Space},
  author = {De, Sandip and Bartók, Albert P. and Csányi, Gábor and Ceriotti, Michele},
  date = {2016-05-18},
  journaltitle = {Physical Chemistry Chemical Physics},
  shortjournal = {Phys. Chem. Chem. Phys.},
  volume = {18},
  number = {20},
  pages = {13754--13769},
  publisher = {{The Royal Society of Chemistry; http://web.archive.org/web/20200619022204/https://pubs.rsc.org/en/content/articlelanding/2016/cp/c6cp00415f}},
  issn = {1463-9084},
  doi = {10.1039/C6CP00415F},
  url = {10.1039/C6CP00415F},
  urldate = {2020-06-19},
  abstract = {Evaluating the (dis)similarity of crystalline, disordered and molecular compounds is a critical step in the development of algorithms to navigate automatically the configuration space of complex materials. For instance, a structural similarity metric is crucial for classifying structures, searching chemical space for better compounds and materials, and driving the next generation of machine-learning techniques for predicting the stability and properties of molecules and materials. In the last few years several strategies have been designed to compare atomic coordination environments. In particular, the smooth overlap of atomic positions (SOAPs) has emerged as an elegant framework to obtain translation, rotation and permutation-invariant descriptors of groups of atoms, underlying the development of various classes of machine-learned inter-atomic potentials. Here we discuss how one can combine such local descriptors using a regularized entropy match (REMatch) approach to describe the similarity of both whole molecular and bulk periodic structures, introducing powerful metrics that enable the navigation of alchemical and structural complexities within a unified framework. Furthermore, using this kernel and a ridge regression method we can predict atomization energies for a database of small organic molecules with a mean absolute error below 1 kcal mol−1, reaching an important milestone in the application of machine-learning techniques for the evaluation of molecular properties.},
  langid = {english}
}

@article{desaiSurveyEvidenceTestdriven2008,
  title = {A Survey of Evidence for Test-Driven Development in Academia},
  author = {Desai, Chetan and Janzen, David and Savage, Kyle},
  date = {2008-06},
  journaltitle = {ACM SIGCSE Bulletin},
  shortjournal = {SIGCSE Bull.},
  volume = {40},
  number = {2},
  pages = {97--101},
  issn = {0097-8418},
  doi = {10.1145/1383602.1383644},
  url = {https://dl.acm.org/doi/10.1145/1383602.1383644},
  urldate = {2022-06-29},
  abstract = {University professors traditionally struggle to incorporate software testing into their course curriculum. Worries include double-grading for correctness of both source and test code and finding time to teach testing as a topic. Test-driven development (TDD) has been suggested as a possible solution to improve student software testing skills and to realize the benefits of testing. According to most existing studies, TDD improves software quality and student productivity. This paper surveys the current state of TDD experiments conducted exclusively at universities. Similar surveys compare experiments in both the classroom and industry, but none have focused strictly on academia.},
  langid = {english}
}

@article{dralQuantumChemistryAge2020,
  title = {Quantum {{Chemistry}} in the {{Age}} of {{Machine Learning}}},
  author = {Dral, Pavlo O.},
  date = {2020-03-19},
  journaltitle = {The Journal of Physical Chemistry Letters},
  shortjournal = {J. Phys. Chem. Lett.},
  volume = {11},
  number = {6},
  pages = {2336--2347},
  publisher = {{American Chemical Society; http://web.archive.org/web/20200622155222/https://pubs.acs.org/doi/10.1021/acs.jpclett.9b03664}},
  doi = {10.1021/acs.jpclett.9b03664},
  url = {10.1021/acs.jpclett.9b03664},
  urldate = {2020-06-22},
  abstract = {As the quantum chemistry (QC) community embraces machine learning (ML), the number of new methods and applications based on the combination of QC and ML is surging. In this Perspective, a view of the current state of affairs in this new and exciting research field is offered, challenges of using machine learning in quantum chemistry applications are described, and potential future developments are outlined. Specifically, examples of how machine learning is used to improve the accuracy and accelerate quantum chemical research are shown. Generalization and classification of existing techniques are provided to ease the navigation in the sea of literature and to guide researchers entering the field. The emphasis of this Perspective is on supervised machine learning.}
}

@unpublished{engstromIdentifyingStatisticalBias2020,
  title = {Identifying {{Statistical Bias}} in {{Dataset Replication}}},
  author = {Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Steinhardt, Jacob and Madry, Aleksander},
  date = {2020-05-19},
  eprint = {2005.09619},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  url = {http://arxiv.org/abs/2005.09619},
  urldate = {2020-06-09},
  abstract = {Dataset replication is a useful tool for assessing whether improvements in test accuracy on a specific benchmark correspond to improvements in models' ability to generalize reliably. In this work, we present unintuitive yet significant ways in which standard approaches to dataset replication introduce statistical bias, skewing the resulting observations. We study ImageNet-v2, a replication of the ImageNet dataset on which models exhibit a significant (11-14\%) drop in accuracy, even after controlling for a standard human-in-the-loop measure of data quality. We show that after correcting for the identified statistical bias, only an estimated \$3.6\textbackslash\% \textbackslash pm 1.5\textbackslash\%\$ of the original \$11.7\textbackslash\% \textbackslash pm 1.0\textbackslash\%\$ accuracy drop remains unaccounted for. We conclude with concrete recommendations for recognizing and avoiding bias in dataset replication. Code for our study is publicly available at http://github.com/MadryLab/dataset-replication-analysis .},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{gaoMachineLearningCorrection2016,
  title = {A Machine Learning Correction for {{DFT}} Non-Covalent Interactions Based on the {{S22}}, {{S66}} and {{X40}} Benchmark Databases},
  author = {Gao, Ting and Li, Hongzhi and Li, Wenze and Li, Lin and Fang, Chao and Li, Hui and Hu, LiHong and Lu, Yinghua and Su, Zhong-Min},
  date = {2016-05-03},
  journaltitle = {Journal of Cheminformatics},
  shortjournal = {Journal of Cheminformatics},
  volume = {8},
  number = {1},
  pages = {24},
  issn = {1758-2946},
  doi = {10.1186/s13321-016-0133-7},
  url = {https://doi.org/10.1186/s13321-016-0133-7},
  urldate = {2020-12-08},
  abstract = {Non-covalent interactions (NCIs) play critical roles in supramolecular chemistries; however, they are difficult to measure. Currently, reliable computational methods are being pursued to meet this challenge, but the accuracy of calculations based on low levels of theory is not satisfactory and calculations based on high levels of theory are often too costly. Accordingly, to reduce the cost and increase the accuracy of low-level theoretical calculations to describe NCIs, an efficient approach is proposed to correct NCI calculations based on the benchmark databases S22, S66 and X40 (Hobza in Acc Chem Rev 45: 663–672, 2012; Řezáč et al. in J Chem Theory Comput 8:4285, 2012).},
  keywords = {Computational accuracy,Density functional theory,Feature selection,Machine learning correction,Non-covalent interactions}
}

@article{hafnerAbinitioSimulationsMaterials2008,
  title = {Ab-Initio Simulations of Materials Using {{VASP}}: {{Density-functional}} Theory and Beyond},
  shorttitle = {Ab-Initio Simulations of Materials Using {{VASP}}},
  author = {Hafner, Jürgen},
  date = {2008},
  journaltitle = {Journal of Computational Chemistry},
  volume = {29},
  number = {13},
  pages = {2044--2078},
  issn = {1096-987X},
  doi = {10.1002/jcc.21057},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.21057},
  urldate = {2022-06-29},
  abstract = {During the past decade, computer simulations based on a quantum-mechanical description of the interactions between electrons and between electrons and atomic nuclei have developed an increasingly important impact on solid-state physics and chemistry and on materials science—promoting not only a deeper understanding, but also the possibility to contribute significantly to materials design for future technologies. This development is based on two important columns: (i) The improved description of electronic many-body effects within density-functional theory (DFT) and the upcoming post-DFT methods. (ii) The implementation of the new functionals and many-body techniques within highly efficient, stable, and versatile computer codes, which allow to exploit the potential of modern computer architectures. In this review, I discuss the implementation of various DFT functionals [local-density approximation (LDA), generalized gradient approximation (GGA), meta-GGA, hybrid functional mixing DFT, and exact (Hartree-Fock) exchange] and post-DFT approaches [DFT + U for strong electronic correlations in narrow bands, many-body perturbation theory (GW) for quasiparticle spectra, dynamical correlation effects via the adiabatic-connection fluctuation-dissipation theorem (AC-FDT)] in the Vienna ab initio simulation package VASP. VASP is a plane-wave all-electron code using the projector-augmented wave method to describe the electron-core interaction. The code uses fast iterative techniques for the diagonalization of the DFT Hamiltonian and allows to perform total-energy calculations and structural optimizations for systems with thousands of atoms and ab initio molecular dynamics simulations for ensembles with a few hundred atoms extending over several tens of ps. Applications in many different areas (structure and phase stability, mechanical and dynamical properties, liquids, glasses and quasicrystals, magnetism and magnetic nanostructures, semiconductors and insulators, surfaces, interfaces and thin films, chemical reactions, and catalysis) are reviewed. © 2008 Wiley Periodicals, Inc. J Comput Chem, 2008},
  langid = {english},
  keywords = {catalysis,density-functional theory,hybrid functionals,many-body perturbation theory,materials science,plane-wave basis,projector-augmented-waves,pseudopotentials,solid state chemistry,solid state physics,surface science},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.21057}
}

@article{hojaQM7XComprehensiveDataset2021,
  title = {{{QM7-X}}, a Comprehensive Dataset of Quantum-Mechanical Properties Spanning the Chemical Space of Small Organic Molecules},
  author = {Hoja, Johannes and Medrano Sandonas, Leonardo and Ernst, Brian G. and Vazquez-Mayagoitia, Alvaro and DiStasio Jr., Robert A. and Tkatchenko, Alexandre},
  date = {2021-02-02},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {8},
  number = {1},
  pages = {43},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/s41597-021-00812-2},
  url = {https://www.nature.com/articles/s41597-021-00812-2},
  urldate = {2022-06-30},
  abstract = {We introduce QM7-X, a comprehensive dataset of 42 physicochemical properties for ≈4.2 million equilibrium and non-equilibrium structures of small organic molecules with up to seven non-hydrogen (C, N, O, S, Cl) atoms. To span this fundamentally important region of chemical compound space (CCS), QM7-X includes an exhaustive sampling of (meta-)stable equilibrium structures—comprised of constitutional/structural isomers and stereoisomers, e.g., enantiomers and diastereomers (including cis-/trans- and conformational isomers)—as well as 100 non-equilibrium structural variations thereof to reach a total of ≈4.2 million molecular structures. Computed at the tightly converged quantum-mechanical PBE0+MBD level of theory,~QM7-X contains global (molecular) and local (atom-in-a-molecule) properties ranging from ground state quantities (such as atomization energies and dipole moments) to response quantities (such as polarizability tensors and dispersion coefficients). By providing a systematic, extensive, and tightly-converged dataset of quantum-mechanically computed physicochemical properties, we expect that QM7-X will play a critical role in the development of next-generation machine-learning based models for exploring greater swaths of CCS and performing in silico design of molecules with targeted properties.},
  issue = {1},
  langid = {english},
  keywords = {Chemical physics,Cheminformatics,Computational chemistry,Physics - Chemical Physics}
}

@article{huberAiiDAScalableComputational2020,
  title = {{{AiiDA}} 1.0, a Scalable Computational Infrastructure for Automated Reproducible Workflows and Data Provenance},
  author = {Huber, Sebastiaan P. and Zoupanos, Spyros and Uhrin, Martin and Talirz, Leopold and Kahle, Leonid and Häuselmann, Rico and Gresch, Dominik and Müller, Tiziano and Yakutovich, Aliaksandr V. and Andersen, Casper W. and Ramirez, Francisco F. and Adorf, Carl S. and Gargiulo, Fernando and Kumbhar, Snehal and Passaro, Elsa and Johnston, Conrad and Merkys, Andrius and Cepellotti, Andrea and Mounet, Nicolas and Marzari, Nicola and Kozinsky, Boris and Pizzi, Giovanni},
  date = {2020-09-08},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {7},
  number = {1},
  pages = {300},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/s41597-020-00638-4},
  url = {https://www.nature.com/articles/s41597-020-00638-4},
  urldate = {2022-06-30},
  abstract = {The ever-growing availability of computing power and the sustained development of advanced computational methods have contributed much to recent scientific progress. These developments present new challenges driven by the sheer amount of calculations and data to manage. Next-generation exascale supercomputers will harden these challenges, such that automated and scalable solutions become crucial. In recent years, we have been developing AiiDA (aiida.net), a robust open-source high-throughput infrastructure addressing the challenges arising from the needs of automated workflow management and data provenance recording. Here, we introduce developments and capabilities required to reach sustained performance, with AiiDA supporting throughputs of tens of thousands processes/hour, while automatically preserving and storing the full data provenance in a relational database making it queryable and traversable, thus enabling high-performance data analytics. AiiDA’s workflow language provides advanced automation, error handling features and a flexible plugin model to allow interfacing with external simulation software. The associated plugin registry enables seamless sharing of extensions, empowering a vibrant user community dedicated to making simulations more robust, user-friendly and reproducible.},
  issue = {1},
  langid = {english},
  keywords = {Computational methods,Computer Science - Distributed; Parallel; and Cluster Computing,Condensed Matter - Materials Science,Research management}
}

@article{kohnNobelLectureElectronic1999,
  title = {Nobel {{Lecture}}: {{Electronic}} Structure of Matter---Wave Functions and Density Functionals},
  shorttitle = {Nobel {{Lecture}}},
  author = {Kohn, W.},
  date = {1999-10-01},
  journaltitle = {Reviews of Modern Physics},
  shortjournal = {Rev. Mod. Phys.},
  volume = {71},
  number = {5},
  pages = {1253--1266},
  publisher = {{American Physical Society}},
  doi = {10.1103/RevModPhys.71.1253},
  url = {https://link.aps.org/doi/10.1103/RevModPhys.71.1253},
  urldate = {2020-03-20}
}

@article{kolosImprovedTheoreticalGround1968,
  title = {Improved {{Theoretical Ground}}‐{{State Energy}} of the {{Hydrogen Molecule}}},
  author = {Kolos, W. and Wolniewicz, L.},
  date = {1968-07-01},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {49},
  number = {1},
  pages = {404--410},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/1.1669836},
  url = {10.1063/1.1669836},
  urldate = {2020-11-17}
}

@article{larsenAtomicSimulationEnvironment2017,
  title = {The Atomic Simulation Environment—a {{Python}} Library for Working with Atoms},
  author = {Larsen, Ask Hjorth and Mortensen, Jens Jørgen and Blomqvist, Jakob and Castelli, Ivano E. and Christensen, Rune and Du\textbackslash lak, Marcin and Friis, Jesper and Groves, Michael N. and Hammer, Bjørk and Hargus, Cory and Hermes, Eric D. and Jennings, Paul C. and Jensen, Peter Bjerre and Kermode, James and Kitchin, John R. and Kolsbjerg, Esben Leonhard and Kubal, Joseph and Kaasbjerg, Kristen and Lysgaard, Steen and Maronsson, Jón Bergmann and Maxson, Tristan and Olsen, Thomas and Pastewka, Lars and Peterson, Andrew and Rostgaard, Carsten and Schiøtz, Jakob and Schütt, Ole and Strange, Mikkel and Thygesen, Kristian S. and Vegge, Tejs and Vilhelmsen, Lasse and Walter, Michael and Zeng, Zhenhua and Jacobsen, Karsten W.},
  date = {2017-06},
  journaltitle = {Journal of Physics: Condensed Matter},
  shortjournal = {J. Phys.: Condens. Matter},
  volume = {29},
  number = {27},
  pages = {273002},
  issn = {0953-8984},
  doi = {10.1088/1361-648X/aa680e},
  url = {https://doi.org/10.1088%2F1361-648x%2Faa680e},
  urldate = {2020-01-24},
  abstract = {The atomic simulation environment (ASE) is a software package written in the Python programming language with the aim of setting up, steering, and analyzing atomistic simulations. In ASE, tasks are fully scripted in Python. The powerful syntax of Python combined with the NumPy array library make it possible to perform very complex simulation tasks. For example, a sequence of calculations may be performed with the use of a simple ‘for-loop’ construction. Calculations of energy, forces, stresses and other quantities are performed through interfaces to many external electronic structure codes or force fields using a uniform interface. On top of this calculator interface, ASE provides modules for performing many standard simulation tasks such as structure optimization, molecular dynamics, handling of constraints and performing nudged elastic band calculations.},
  langid = {english}
}

@article{meyerMachineLearningComputational2019,
  title = {Machine {{Learning}} in {{Computational Chemistry}}: {{An Evaluation}} of {{Method Performance}} for {{Nudged Elastic Band Calculations}}},
  shorttitle = {Machine {{Learning}} in {{Computational Chemistry}}},
  author = {Meyer, Ralf and Schmuck, Klemens S. and Hauser, Andreas W.},
  date = {2019-11-12},
  journaltitle = {Journal of Chemical Theory and Computation},
  shortjournal = {J. Chem. Theory Comput.},
  volume = {15},
  number = {11},
  pages = {6513--6523},
  publisher = {{American Chemical Society}},
  issn = {1549-9618},
  doi = {10.1021/acs.jctc.9b00708},
  url = {https://doi.org/10.1021/acs.jctc.9b00708},
  urldate = {2020-03-29},
  abstract = {The localization of transition states and the calculation of reaction pathways are routine tasks of computational chemists but often very CPU-intense problems, in particular for large systems. The standard algorithm for this purpose is the nudged elastic band method, but it has become obvious that an “intelligent” selection of points to be evaluated on the potential energy surface can improve its convergence significantly. This article summarizes, compares, and extends known strategies that have been heavily inspired by the machine learning developments of recent years. It presents advantages and disadvantages and provides an unbiased comparison of neural network based approaches, Gaussian process regression in Cartesian coordinates, and Gaussian approximation potentials. We test their performance on two example reactions, the ethane rotation and the activation of carbon dioxide on a metal catalyst, and provide a clear ranking in terms of usability for future implementations.},
  keywords = {\#nosource}
}

@article{millmanPythonScientistsEngineers2011,
  title = {Python for {{Scientists}} and {{Engineers}}},
  author = {Millman, K. J. and Aivazis, M.},
  date = {2011-03},
  journaltitle = {Computing in Science Engineering},
  volume = {13},
  number = {2},
  pages = {9--12},
  doi = {10/dc343g},
  abstract = {Python has arguably become the de facto standard for exploratory, interactive, and computation-driven scientific research. This issue discusses Python's advantages for scientific research and presents several of the core Python libraries and tools used in scientific research.},
  keywords = {\#nosource,Computer languages,interactive research,Numerical models,Programming,Programming languages,Python,Python libraries,Python tools,Scientific computing,Special issues and sections}
}

@article{neeseORCAProgramSystem2012,
  title = {The {{ORCA}} Program System},
  author = {Neese, Frank},
  date = {2012},
  journaltitle = {WIREs Computational Molecular Science},
  volume = {2},
  number = {1},
  pages = {73--78},
  issn = {1759-0884},
  doi = {10.1002/wcms.81},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.81},
  urldate = {2022-06-28},
  abstract = {ORCA is a general-purpose quantum chemistry program package that features virtually all modern electronic structure methods (density functional theory, many-body perturbation and coupled cluster theories, and multireference and semiempirical methods). It is designed with the aim of generality, extendibility, efficiency, and user friendliness. Its main field of application is larger molecules, transition metal complexes, and their spectroscopic properties. ORCA uses standard Gaussian basis functions and is fully parallelized. The article provides an overview of its current possibilities and documents its efficiency. © 2011 John Wiley \& Sons, Ltd. This article is categorized under: Software {$>$} Quantum Chemistry},
  langid = {english},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.81}
}

@article{neeseORCAQuantumChemistry2020,
  title = {The {{ORCA}} Quantum Chemistry Program Package},
  author = {Neese, Frank and Wennmohs, Frank and Becker, Ute and Riplinger, Christoph},
  date = {2020-06-12},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {152},
  number = {22},
  pages = {224108},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/5.0004608},
  url = {https://aip.scitation.org/doi/10.1063/5.0004608},
  urldate = {2020-11-28},
  abstract = {In this contribution to the special software-centered issue, the ORCA program package is described. We start with a short historical perspective of how the project began and go on to discuss its current feature set. ORCA has grown into a rather comprehensive general-purpose package for theoretical research in all areas of chemistry and many neighboring disciplines such as materials sciences and biochemistry. ORCA features density functional theory, a range of wavefunction based correlation methods, semi-empirical methods, and even force-field methods. A range of solvation and embedding models is featured as well as a complete intrinsic to ORCA quantum mechanics/molecular mechanics engine. A specialty of ORCA always has been a focus on transition metals and spectroscopy as well as a focus on applicability of the implemented methods to “real-life” chemical applications involving systems with a few hundred atoms. In addition to being efficient, user friendly, and, to the largest extent possible, platform independent, ORCA features a number of methods that are either unique to ORCA or have been first implemented in the course of the ORCA development. Next to a range of spectroscopic and magnetic properties, the linear- or low-order single- and multi-reference local correlation methods based on pair natural orbitals (domain based local pair natural orbital methods) should be mentioned here. Consequently, ORCA is a widely used program in various areas of chemistry and spectroscopy with a current user base of over 22 000 registered users in academic research and in industry.}
}

@article{neeseORCAQuantumChemistry2020a,
  title = {The {{ORCA}} Quantum Chemistry Program Package},
  author = {Neese, Frank and Wennmohs, Frank and Becker, Ute and Riplinger, Christoph},
  date = {2020-06-12},
  journaltitle = {The Journal of Chemical Physics},
  shortjournal = {J. Chem. Phys.},
  volume = {152},
  number = {22},
  pages = {224108},
  publisher = {{American Institute of Physics}},
  issn = {0021-9606},
  doi = {10.1063/5.0004608},
  url = {https://aip.scitation.org/doi/full/10.1063/5.0004608},
  urldate = {2021-06-07},
  abstract = {In this contribution to the special software-centered issue, the ORCA program package is described. We start with a short historical perspective of how the project began and go on to discuss its current feature set. ORCA has grown into a rather comprehensive general-purpose package for theoretical research in all areas of chemistry and many neighboring disciplines such as materials sciences and biochemistry. ORCA features density functional theory, a range of wavefunction based correlation methods, semi-empirical methods, and even force-field methods. A range of solvation and embedding models is featured as well as a complete intrinsic to ORCA quantum mechanics/molecular mechanics engine. A specialty of ORCA always has been a focus on transition metals and spectroscopy as well as a focus on applicability of the implemented methods to “real-life” chemical applications involving systems with a few hundred atoms. In addition to being efficient, user friendly, and, to the largest extent possible, platform independent, ORCA features a number of methods that are either unique to ORCA or have been first implemented in the course of the ORCA development. Next to a range of spectroscopic and magnetic properties, the linear- or low-order single- and multi-reference local correlation methods based on pair natural orbitals (domain based local pair natural orbital methods) should be mentioned here. Consequently, ORCA is a widely used program in various areas of chemistry and spectroscopy with a current user base of over 22 000 registered users in academic research and in industry.}
}

@article{oboyleCclibLibraryPackageindependent2008a,
  title = {Cclib: {{A}} Library for Package-Independent Computational Chemistry Algorithms},
  shorttitle = {Cclib},
  author = {O'boyle, Noel M. and Tenderholt, Adam L. and Langner, Karol M.},
  date = {2008},
  journaltitle = {Journal of Computational Chemistry},
  volume = {29},
  number = {5},
  pages = {839--845},
  issn = {1096-987X},
  doi = {10.1002/jcc.20823},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jcc.20823},
  urldate = {2022-06-28},
  abstract = {There are now a wide variety of packages for electronic structure calculations, each of which differs in the algorithms implemented and the output format. Many computational chemistry algorithms are only available to users of a particular package despite being generally applicable to the results of calculations by any package. Here we present cclib, a platform for the development of package-independent computational chemistry algorithms. Files from several versions of multiple electronic structure packages are automatically detected, parsed, and the extracted information converted to a standard internal representation. A number of population analysis algorithms have been implemented as a proof of principle. In addition, cclib is currently used as an input filter for two GUI applications that analyze output files: PyMOlyze and GaussSum. © 2007 Wiley Periodicals, Inc. J Comput Chem, 2008},
  langid = {english},
  keywords = {algorithms,computational chemistry,Python},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/jcc.20823}
}

@article{oliphantPythonScientificComputing2007,
  title = {Python for {{Scientific Computing}}},
  author = {Oliphant, T. E.},
  date = {2007-05},
  journaltitle = {Computing in Science Engineering},
  volume = {9},
  number = {3},
  pages = {10--20},
  issn = {1521-9615},
  doi = {10/fjzzc8},
  abstract = {Python is an excellent "steering" language for scientific codes written in other languages. However, with additional basic tools, Python transforms into a high-level language suited for scientific and engineering code that's often fast enough to be immediately useful but also flexible enough to be sped up with additional extensions.},
  keywords = {Application software,computer languages,Embedded software,high level languages,High level languages,high-level language,Internet,Libraries,Prototypes,Python,scientific codes,scientific computing,Scientific computing,scientific programming,Software standards,Standards development,steering language,Writing},
  annotation = {02159}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  author = {Peng, Roger D.},
  date = {2011-12-02},
  journaltitle = {Science},
  volume = {334},
  number = {6060},
  eprint = {22144613},
  eprinttype = {pmid},
  pages = {1226--1227},
  issn = {0036-8075, 1095-9203},
  doi = {10/fdv356},
  url = {https://science.sciencemag.org/content/334/6060/1226},
  urldate = {2019-09-04},
  abstract = {{$<$}p{$>$}Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.{$<$}/p{$>$}},
  langid = {english},
  annotation = {00860}
}

@article{pizziAiiDAAutomatedInteractive2016,
  title = {{{AiiDA}}: Automated Interactive Infrastructure and Database for Computational Science},
  shorttitle = {{{AiiDA}}},
  author = {Pizzi, Giovanni and Cepellotti, Andrea and Sabatini, Riccardo and Marzari, Nicola and Kozinsky, Boris},
  date = {2016-01-01},
  journaltitle = {Computational Materials Science},
  shortjournal = {Computational Materials Science},
  volume = {111},
  pages = {218--230},
  issn = {0927-0256},
  doi = {10.1016/j.commatsci.2015.09.013},
  url = {http://www.sciencedirect.com/science/article/pii/S0927025615005820},
  urldate = {2020-07-07},
  abstract = {Computational science has seen in the last decades a spectacular rise in the scope, breadth, and depth of its efforts. Notwithstanding this prevalence and impact, it is often still performed using the renaissance model of individual artisans gathered in a workshop, under the guidance of an established practitioner. Great benefits could follow instead from adopting concepts and tools coming from computer science to manage, preserve, and share these computational efforts. We illustrate here our paradigm sustaining such vision, based around the four pillars of Automation, Data, Environment, and Sharing. We then discuss its implementation in the open-source AiiDA platform (http://www.aiida.net), that has been tuned first to the demands of computational materials science. AiiDA’s design is based on directed acyclic graphs to track the provenance of data and calculations, and ensure preservation and searchability. Remote computational resources are managed transparently, and automation is coupled with data storage to ensure reproducibility. Last, complex sequences of calculations can be encoded into scientific workflows. We believe that AiiDA’s design and its sharing capabilities will encourage the creation of social ecosystems to disseminate codes, data, and scientific workflows.},
  langid = {english},
  keywords = {Directed acyclic graph,High-throughput,Materials database,Provenance,Reproducibility,Scientific workflow}
}

@inproceedings{rahamanSpectralBiasNeural2019,
  title = {On the {{Spectral Bias}} of {{Neural Networks}}},
  booktitle = {Proceedings of the 36th {{International Conference}} on {{Machine Learning}}},
  author = {Rahaman, Nasim and Baratin, Aristide and Arpit, Devansh and Draxler, Felix and Lin, Min and Hamprecht, Fred and Bengio, Yoshua and Courville, Aaron},
  date = {2019-05-24},
  pages = {5301--5310},
  publisher = {{PMLR}},
  issn = {2640-3498},
  url = {https://proceedings.mlr.press/v97/rahaman19a.html},
  urldate = {2022-06-30},
  abstract = {Neural networks are known to be a class of highly expressive functions able to fit even random input-output mappings with 100\% accuracy. In this work we present properties of neural networks that complement this aspect of expressivity. By using tools from Fourier analysis, we highlight a learning bias of deep networks towards low frequency functions – i.e. functions that vary globally without local fluctuations – which manifests itself as a frequency-dependent learning speed. Intuitively, this property is in line with the observation that over-parameterized networks prioritize learning simple patterns that generalize across data samples. We also investigate the role of the shape of the data manifold by presenting empirical and theoretical evidence that, somewhat counter-intuitively, learning higher frequencies gets easier with increasing manifold complexity.},
  eventtitle = {International {{Conference}} on {{Machine Learning}}},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning}
}

@article{sandveTenSimpleRules2013,
  title = {Ten {{Simple Rules}} for {{Reproducible Computational Research}}},
  author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
  date = {2013-10-24},
  journaltitle = {PLOS Computational Biology},
  shortjournal = {PLOS Computational Biology},
  volume = {9},
  number = {10},
  pages = {e1003285},
  issn = {1553-7358},
  doi = {10/pjb},
  url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
  urldate = {2019-09-04},
  langid = {english},
  keywords = {Archives,Computer and information sciences,Computer applications,Habits,Replication studies,Reproducibility,Sequence analysis,Source code},
  annotation = {00398}
}

@article{schaeferMethyleneParadigmComputational1986,
  title = {Methylene: {{A Paradigm}} for {{Computational Quantum Chemistry}}},
  shorttitle = {Methylene},
  author = {Schaefer, Henry F.},
  date = {1986-03-07},
  journaltitle = {Science},
  volume = {231},
  number = {4742},
  eprint = {17818539; http://web.archive.org/web/20200929150418/https://science.sciencemag.org/content/231/4742/1100},
  eprinttype = {pmid},
  pages = {1100--1107},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.231.4742.1100},
  url = {10.1126/science.231.4742.1100},
  urldate = {2020-09-29},
  abstract = {The year 1970 has been suggested as a starting date for the "third age of quantum chemistry," in which theory takes on not only qualitative but also quantitative value. In fact, each of the years 1960, 1970, 1972, and 1977 is of historical value in the unraveling of the structure and energetics of the CH2 molecule, methylene. What took place for methylene, namely the establishment of credibility for theory, has subsequently taken place for many other molecules. Three important roles for quantitative theory are outlined: (i) theory precedes experiment; (ii) theory overturns experiment, as resolved by later experiments; and (iii) theory and experiment work together to gain insight that is afforded independently to neither. Several examples from each of the three classes are given.},
  langid = {english}
}

@article{schuttUnifyingMachineLearning2019,
  title = {Unifying Machine Learning and Quantum Chemistry with a Deep Neural Network for Molecular Wavefunctions},
  author = {Schütt, K. T. and Gastegger, M. and Tkatchenko, A. and Müller, K.-R. and Maurer, R. J.},
  date = {2019-11-15},
  journaltitle = {Nature Communications},
  volume = {10},
  number = {1},
  pages = {5024},
  publisher = {{Nature Publishing Group; http://web.archive.org/web/20200928122955/https://www.nature.com/articles/s41467-019-12875-2}},
  issn = {2041-1723},
  doi = {10.1038/s41467-019-12875-2},
  url = {10.1038/s41467-019-12875-2},
  urldate = {2020-09-28},
  abstract = {Machine learning advances chemistry and materials science by enabling large-scale exploration of chemical space based on quantum chemical calculations. While these models supply fast and accurate predictions of atomistic chemical properties, they do not explicitly capture the electronic degrees of freedom of a molecule, which limits their applicability for reactive chemistry and chemical analysis. Here we present a deep learning framework for the prediction of the quantum mechanical wavefunction in a local basis of atomic orbitals from which all other ground-state properties can be derived. This approach retains full access to the electronic structure via the wavefunction at force-field-like efficiency and captures quantum mechanics in an analytically differentiable representation. On several examples, we demonstrate that this opens promising avenues to perform inverse design of molecular structures for targeting electronic property optimisation and a clear path towards increased synergy of machine learning and quantum chemistry.},
  issue = {1},
  langid = {english}
}

@article{seniorProteinStructurePrediction2019,
  title = {Protein Structure Prediction Using Multiple Deep Neural Networks in the 13th {{Critical Assessment}} of {{Protein Structure Prediction}} ({{CASP13}})},
  author = {Senior, Andrew W. and Evans, Richard and Jumper, John and Kirkpatrick, James and Sifre, Laurent and Green, Tim and Qin, Chongli and Žídek, Augustin and Nelson, Alexander W. R. and Bridgland, Alex and Penedones, Hugo and Petersen, Stig and Simonyan, Karen and Crossan, Steve and Kohli, Pushmeet and Jones, David T. and Silver, David and Kavukcuoglu, Koray and Hassabis, Demis},
  date = {2019},
  journaltitle = {Proteins: Structure, Function, and Bioinformatics},
  volume = {87},
  number = {12},
  pages = {1141--1148},
  issn = {1097-0134},
  doi = {10.1002/prot.25834},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/prot.25834},
  urldate = {2020-04-05},
  abstract = {We describe AlphaFold, the protein structure prediction system that was entered by the group A7D in CASP13. Submissions were made by three free-modeling (FM) methods which combine the predictions of three neural networks. All three systems were guided by predictions of distances between pairs of residues produced by a neural network. Two systems assembled fragments produced by a generative neural network, one using scores from a network trained to regress GDT\_TS. The third system shows that simple gradient descent on a properly constructed potential is able to perform on par with more expensive traditional search techniques and without requiring domain segmentation. In the CASP13 FM assessors' ranking by summed z-scores, this system scored highest with 68.3 vs 48.2 for the next closest group (an average GDT\_TS of 61.4). The system produced high-accuracy structures (with GDT\_TS scores of 70 or higher) for 11 out of 43 FM domains. Despite not explicitly using template information, the results in the template category were comparable to the best performing template-based methods.},
  langid = {english},
  keywords = {CASP,deep learning,machine learning,protein structure prediction},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/prot.25834}
}

@article{smithMolSSIQCArchiveProject2021,
  title = {The {{MolSSI QCArchive}} Project: {{An}} Open-Source Platform to Compute, Organize, and Share Quantum Chemistry Data},
  shorttitle = {The {{MolSSI QCArchive}} Project},
  author = {Smith, Daniel G. A. and Altarawy, Doaa and Burns, Lori A. and Welborn, Matthew and Naden, Levi N. and Ward, Logan and Ellis, Sam and Pritchard, Benjamin P. and Crawford, T. Daniel},
  date = {2021},
  journaltitle = {WIREs Computational Molecular Science},
  volume = {11},
  number = {2},
  pages = {e1491},
  issn = {1759-0884},
  doi = {10.1002/wcms.1491},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wcms.1491},
  urldate = {2022-06-28},
  abstract = {The Molecular Sciences Software Institute's (MolSSI) Quantum Chemistry Archive (QCArchive) project is an umbrella name that covers both a central server hosted by MolSSI for community data and the Python-based software infrastructure that powers automated computation and storage of quantum chemistry (QC) results. The MolSSI-hosted central server provides the computational molecular sciences community a location to freely access tens of millions of QC computations for machine learning, methodology assessment, force-field fitting, and more through a Python interface. Facile, user-friendly mining of the centrally archived quantum chemical data also can be achieved through web applications found at https://qcarchive.molssi.org. The software infrastructure can be used as a standalone platform to compute, structure, and distribute hundreds of millions of QC computations for individuals or groups of researchers at any scale. The QCArchive Infrastructure is open-source (BSD-3C), code repositories can be found at https://github.com/MolSSI, and releases can be downloaded via PyPI and Conda. This article is categorized under: Electronic Structure Theory {$>$} Ab Initio Electronic Structure Methods Software {$>$} Quantum Chemistry Data Science {$>$} Computer Algorithms and Programming},
  langid = {english},
  keywords = {databases,density functional theory,high-throughput computing,machine learning,quantum chemistry.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wcms.1491}
}

@article{virtanenSciPyFundamentalAlgorithms2020,
  title = {{{SciPy}} 1.0: Fundamental Algorithms for Scientific Computing in {{Python}}},
  shorttitle = {{{SciPy}} 1.0},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and van der Walt, Stéfan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C. J. and Polat, İlhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Antônio H. and Pedregosa, Fabian and van Mulbregt, Paul},
  options = {useprefix=true},
  date = {2020-03},
  journaltitle = {Nature Methods},
  shortjournal = {Nat Methods},
  volume = {17},
  number = {3},
  pages = {261--272},
  publisher = {{Nature Publishing Group}},
  issn = {1548-7105},
  doi = {10.1038/s41592-019-0686-2},
  url = {https://www.nature.com/articles/s41592-019-0686-2},
  urldate = {2021-07-13},
  abstract = {SciPy is an open-source scientific computing library for the Python programming language. Since its initial release in 2001, SciPy has become a de facto standard for leveraging scientific algorithms in Python, with over 600 unique code contributors, thousands of dependent packages, over 100,000 dependent repositories and millions of downloads per year. In this work, we provide an overview of the capabilities and development practices of SciPy 1.0 and highlight some recent technical developments.},
  issue = {3},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Reviews Subject\_term: Biophysical chemistry;Computational biology and bioinformatics;Technology Subject\_term\_id: biophysical-chemistry;computational-biology-and-bioinformatics;technology}
}

@article{wickhamWelcomeTidyverse2019,
  title = {Welcome to the {{Tidyverse}}},
  author = {Wickham, Hadley and Averick, Mara and Bryan, Jennifer and Chang, Winston and McGowan, Lucy D'Agostino and François, Romain and Grolemund, Garrett and Hayes, Alex and Henry, Lionel and Hester, Jim and Kuhn, Max and Pedersen, Thomas Lin and Miller, Evan and Bache, Stephan Milton and Müller, Kirill and Ooms, Jeroen and Robinson, David and Seidel, Dana Paige and Spinu, Vitalie and Takahashi, Kohske and Vaughan, Davis and Wilke, Claus and Woo, Kara and Yutani, Hiroaki},
  date = {2019-11-21},
  journaltitle = {Journal of Open Source Software},
  volume = {4},
  number = {43},
  pages = {1686},
  issn = {2475-9066},
  doi = {10.21105/joss.01686},
  url = {10.21105/joss.01686},
  urldate = {2020-11-28},
  abstract = {Wickham et al., (2019). Welcome to the Tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686},
  langid = {english}
}

@book{wilkinsonGrammarGraphics2005,
  title = {The Grammar of Graphics},
  author = {Wilkinson, Leland and Wills, Graham},
  date = {2005},
  series = {Statistics and Computing},
  edition = {2nd ed},
  publisher = {{Springer}},
  location = {{New York}},
  isbn = {978-0-387-24544-7},
  pagetotal = {690},
  keywords = {Graphic methods Data processing,Statistics}
}


